{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f26858a",
   "metadata": {},
   "source": [
    "# Subscriber vs Non-Subscriber Usage Patterns (2018)\n",
    "\n",
    "Goal: explore whether subscribers and non-subscribers use the service differently. Notebook is self-contained; installs and imports are at the top."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e67897e",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Install dependencies. If you already have them, skip this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e984e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas numpy matplotlib scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202390bf",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f86a63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, roc_auc_score, average_precision_score, accuracy_score, confusion_matrix, ConfusionMatrixDisplay, RocCurveDisplay, PrecisionRecallDisplay\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffecf88c",
   "metadata": {},
   "source": [
    "## Load trips + weather\n",
    "- Adds basic time/age features.\n",
    "- Merges hourly weather to trip start hour (extension requested in project guidelines)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9757f5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weather\n",
    "weather = pd.read_csv(\"../data/weather_2018.csv\")\n",
    "weather[\"weather_time\"] = pd.to_datetime(weather[\"datetime\"])\n",
    "weather_features = [\"temp\", \"humidity\", \"precip\", \"windspeed\"]\n",
    "weather = weather[[\"weather_time\"] + weather_features]\n",
    "weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbb2ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips = pd.read_csv(\"../data/processed_trips_2018.csv\")\n",
    "\n",
    "# Parse times\n",
    "trips[\"starttime\"] = pd.to_datetime(trips[\"starttime\"])\n",
    "trips[\"stoptime\"] = pd.to_datetime(trips[\"stoptime\"])\n",
    "\n",
    "# Time related features\n",
    "trips[\"duration_min\"] = trips[\"tripduration\"] / 60\n",
    "trips[\"start_hour\"] = trips[\"starttime\"].dt.floor(\"h\")\n",
    "\n",
    "trips[\"hour\"] = trips[\"starttime\"].dt.hour\n",
    "trips[\"dayofweek\"] = trips[\"starttime\"].dt.day_name()\n",
    "trips[\"month\"] = trips[\"starttime\"].dt.month\n",
    "trips[\"is_weekend\"] = trips[\"starttime\"].dt.dayofweek >= 5\n",
    "\n",
    "# Age (birth_year can be missing or non-numeric)\n",
    "trips[\"birth_year\"] = pd.to_numeric(trips[\"birth_year\"], errors=\"coerce\")\n",
    "trips[\"age\"] = 2018 - trips[\"birth_year\"]\n",
    "\n",
    "trips.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cae1555",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips = trips.merge(weather, left_on=\"start_hour\", right_on=\"weather_time\", how=\"left\")\n",
    "\n",
    "print(\"Trips rows:\", len(trips))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4fbb49",
   "metadata": {},
   "source": [
    "## Quick descriptive comparison\n",
    "High-level differences between subscribers and customers before plotting.\n",
    "\n",
    "- Trip counts and ride duration (mean/median)\n",
    "- Age profile (trim obvious outliers)\n",
    "- Gender split and weekend vs weekday mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf92cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trip counts and ride length by user type\n",
    "duration_summary = trips.groupby(\"usertype\")[\"duration_min\"].agg(trips=\"count\", mean_min=\"mean\", median_min=\"median\")\n",
    "\n",
    "duration_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc95746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age, gender, and weekend mix\n",
    "age_summary = (\n",
    "    trips.groupby(\"usertype\")[\"age\"]\n",
    "    .agg(\n",
    "        median_age=\"median\",\n",
    "        mean_age=\"mean\"\n",
    "    ).round(1)\n",
    ")\n",
    "# diagnostics\n",
    "age_diagnostic = (\n",
    "    trips.groupby(\"usertype\")[\"age\"].agg(\n",
    "        count=\"count\",\n",
    "        missing=lambda s: s.isna().sum(),\n",
    "        min_age=\"min\",\n",
    "        q10=lambda s: s.quantile(0.1),\n",
    "        median_age=\"median\",\n",
    "        mean_age=\"mean\",\n",
    "        max_age=\"max\"\n",
    "    ).round(1)\n",
    ")\n",
    "\n",
    "# Plot age histogram for Customer and Subscriber (matplotlib only)\n",
    "bins = range(0, 141, 1)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4), sharex=True, sharey=True)\n",
    "\n",
    "for ax, user in zip(axes, [\"Customer\", \"Subscriber\"]):\n",
    "    ages = trips.loc[trips[\"usertype\"] == user, \"age\"].dropna()\n",
    "    ax.hist(ages, bins=bins, alpha=0.8)\n",
    "    ax.set_title(f\"Age distribution â€” {user}\")\n",
    "    ax.set_xlim(0, 140)\n",
    "    ax.set_xlabel(\"Age\")\n",
    "\n",
    "axes[0].set_ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6f629e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_map = {0: \"Unknown\", 1: \"Male\", 2: \"Female\"}\n",
    "gender_share = (\n",
    "    trips.assign(gender_label=trips[\"gender\"].map(gender_map).fillna(\"Unknown\"))\n",
    "    .groupby([\"usertype\", \"gender_label\"])\n",
    "    .size()\n",
    "    .groupby(level=0)\n",
    "    .apply(lambda s: s / s.sum())\n",
    "    .unstack(fill_value=0)\n",
    "    .round(3)\n",
    "    .sort_index(axis=1)\n",
    ")\n",
    "\n",
    "\n",
    "weekend_mix = (\n",
    "    trips.groupby([\"usertype\", \"is_weekend\"])\n",
    "    .size()\n",
    "    .groupby(level=0)\n",
    "    .apply(lambda s: s / s.sum())\n",
    "    .unstack()\n",
    "    .rename(columns={False: \"weekday_share\", True: \"weekend_share\"})\n",
    "    .fillna(0)\n",
    "    .round(3)\n",
    ")\n",
    "\n",
    "display(gender_share)\n",
    "display(weekend_mix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23ff8a5",
   "metadata": {},
   "source": [
    "## Exploratory visualizations\n",
    "Focus on subscriber vs non-subscriber usage patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbaf3800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trip duration histogram (density) by user type\n",
    "bins = np.linspace(0,120, 120)\n",
    "for user in trips[\"usertype\"].unique():\n",
    "    durations = trips.loc[trips[\"usertype\"] == user, \"duration_min\"]\n",
    "    plt.hist(durations, bins=bins, density=True, histtype=\"step\", linewidth=2, label=user)\n",
    "\n",
    "plt.xlim(0.1, 120)\n",
    "plt.title(\"Trip duration\")\n",
    "plt.xlabel(\"Duration (minutes)\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend(title=\"User type\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81b5a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subscribers vs customers over time (monthly, full dataset)\n",
    "monthly_counts = (\n",
    "    trips.assign(month_start=trips[\"starttime\"].dt.to_period(\"M\").dt.to_timestamp())\n",
    "    .groupby([\"month_start\", \"usertype\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"trips\")\n",
    "    .sort_values(\"month_start\")\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "for user, group in monthly_counts.groupby(\"usertype\"):\n",
    "    plt.plot(group[\"month_start\"], group[\"trips\"], marker=\"o\", label=user)\n",
    "\n",
    "plt.title(\"Monthly trips by user type (full 2018 data)\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Trips\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title=\"User type\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee8a92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hour-of-day pattern\n",
    "hourly = trips.groupby([\"hour\", \"usertype\"]).size().reset_index(name=\"trips\")\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "for user, group in hourly.groupby(\"usertype\"):\n",
    "    plt.plot(group[\"hour\"], group[\"trips\"], marker=\"o\", label=user)\n",
    "plt.title(\"Trips by hour of day\")\n",
    "plt.xlabel(\"Hour of day\")\n",
    "plt.ylabel(\"Trips\")\n",
    "plt.legend(title=\"User type\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Day-of-week pattern\n",
    "order = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "pivot = (\n",
    "    trips.groupby([\"dayofweek\", \"usertype\"]).size().unstack(fill_value=0)\n",
    "    .reindex(order)\n",
    ")\n",
    "\n",
    "x = np.arange(len(order))\n",
    "width = 0.35\n",
    "for i, user in enumerate(pivot.columns):\n",
    "    plt.bar(x + i * width - width / 2, pivot[user], width, label=user)\n",
    "\n",
    "plt.xticks(x, order, rotation=30)\n",
    "plt.ylabel(\"Trips\")\n",
    "plt.title(\"Trips by day of week\")\n",
    "plt.legend(title=\"User type\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c80dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weather sensitivity: trips vs temperature\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "for user, group in trips.groupby(\"usertype\"):\n",
    "    temps = group[\"temp\"].dropna()\n",
    "    plt.hist(temps, bins=30, density=True, alpha=0.6, label=user)\n",
    "\n",
    "plt.title(\"Trips across temperature\")\n",
    "plt.xlabel(\"Temperature\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend(title=\"User type\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1025da1",
   "metadata": {},
   "source": [
    "## Supervised learning: predict subscriber vs non-subscriber\n",
    "We will now train and test two models: Logistic Regression (linear baseline) and Random Forest (non-linear, handles interactions). Features include duration, time-of-day, location, and weather."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04065f29",
   "metadata": {},
   "source": [
    "The full dataset has more than 17 million datapoints which will take very long to train on a cpu. It could be advantageous to utilize the fact that Random Forest can be trained and run in parallel as each tree can be trained on its own node. Unfortunately, however, sklearn does not support cuda or MPS implementation. We could use torch instead of sklearn and/or use DTU's hpc to train the model, but we choose to stick with methods we have used in class, therefore we will now take a subset of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34706fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample = 100000 # Number of samples to include for the supervised learning section\n",
    "trips_sample = trips.sample(n=n_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4720eb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare labeled data for binary classification (no age or gender: high customer missingness)\n",
    "feature_cols = [\n",
    "    \"duration_min\",\n",
    "    \"hour\",\n",
    "    \"start_station_latitude\",\n",
    "    \"start_station_longitude\",\n",
    "    \"temp\",\n",
    "    \"humidity\",\n",
    "    \"precip\",\n",
    "    \"windspeed\",\n",
    "]\n",
    "\n",
    "# Keep rows with all selected features, create target 1=customer, 0=subscriber\n",
    "model_data = trips_sample[feature_cols + [\"usertype\"]].dropna().copy()\n",
    "model_data[\"is_subscriber\"] = (model_data[\"usertype\"] == \"Customer\").astype(int)\n",
    "\n",
    "# Train/test split (simple 80/20 split for logistic regression)\n",
    "split = int(len(model_data) * 0.8)\n",
    "train = model_data.iloc[:split]\n",
    "test = model_data.iloc[split:]\n",
    "\n",
    "X_train = train[feature_cols]\n",
    "X_test = test[feature_cols]\n",
    "y_train = train[\"is_subscriber\"]\n",
    "y_test = test[\"is_subscriber\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5ff423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression baseline (linear decision boundary)\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Train set predictions\n",
    "train_pred = log_reg.predict(X_train)\n",
    "train_proba = log_reg.predict_proba(X_train)[:, 1]\n",
    "\n",
    "# Test set predictions\n",
    "test_pred = log_reg.predict(X_test)\n",
    "test_proba = log_reg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Logistic Regression (train set)\")\n",
    "print(\"Accuracy:\", round(accuracy_score(y_train, train_pred), 3))\n",
    "print(\"F1:      \", round(f1_score(y_train, train_pred), 3))\n",
    "print(\"ROC-AUC: \", round(roc_auc_score(y_train, train_proba), 3))\n",
    "print(\"PR-AUC:  \", round(average_precision_score(y_train, train_proba), 3))\n",
    "\n",
    "print(\"\\nLogistic Regression (test set)\")\n",
    "print(\"Accuracy:\", round(accuracy_score(y_test, test_pred), 3))\n",
    "print(\"F1:      \", round(f1_score(y_test, test_pred), 3))\n",
    "print(\"ROC-AUC: \", round(roc_auc_score(y_test, test_proba), 3))\n",
    "print(\"PR-AUC:  \", round(average_precision_score(y_test, test_proba), 3))\n",
    "\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_test, test_pred), display_labels=[\"Subscriber\", \"Customer\"]).plot(colorbar=False)\n",
    "plt.title(\"Logistic Regression confusion matrix\")\n",
    "plt.show()\n",
    "\n",
    "# ROC and PR curves side by side\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# ROC curve\n",
    "RocCurveDisplay.from_estimator(log_reg, X_test, y_test, ax=axes[0])\n",
    "axes[0].plot([0, 1], [0, 1], linestyle='--', color='gray', label='No Skill Classifier')\n",
    "axes[0].set_title(\"Logistic Regression ROC curve\")\n",
    "axes[0].legend()\n",
    "\n",
    "# Precision-Recall curve\n",
    "no_skill = y_test.mean()\n",
    "PrecisionRecallDisplay.from_estimator(log_reg, X_test, y_test, ax=axes[1])\n",
    "axes[1].axhline(y=no_skill, linestyle='--', color='gray', label='No Skill Classifier')\n",
    "axes[1].set_title(\"Logistic Regression Precision-Recall curve\")\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373fd0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/validation/test split (60/20/20) for Random Forest. Same test set as before\n",
    "n = len(model_data)\n",
    "train_end = int(n * 0.6)\n",
    "val_end = int(n * 0.8)\n",
    "\n",
    "train = model_data.iloc[:train_end]\n",
    "val = model_data.iloc[train_end:val_end]\n",
    "test = model_data.iloc[val_end:]\n",
    "\n",
    "X_train = train[feature_cols]\n",
    "X_val = val[feature_cols]\n",
    "X_test = test[feature_cols]\n",
    "y_train = train[\"is_subscriber\"]\n",
    "y_val = val[\"is_subscriber\"]\n",
    "y_test = test[\"is_subscriber\"]\n",
    "\n",
    "# Define parameter grid to search\n",
    "n_estimators = [50, 100, 200]\n",
    "max_depth = [5, 10, 20, None]\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "for n_est in n_estimators:\n",
    "    for max_d in max_depth:\n",
    "        for min_split in min_samples_split:\n",
    "            rf = RandomForestClassifier(\n",
    "                n_estimators=n_est,\n",
    "                max_depth=max_d,\n",
    "                min_samples_split=min_split,\n",
    "                random_state=42,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            rf.fit(X_train, y_train)\n",
    "            \n",
    "            # Evaluate on validation set\n",
    "            val_proba = rf.predict_proba(X_val)[:, 1]\n",
    "            val_pred = rf.predict(X_val)\n",
    "            val_auc = roc_auc_score(y_val, val_proba)\n",
    "            val_f1 = f1_score(y_val, val_pred)\n",
    "            \n",
    "            results.append({\n",
    "                'n_estimators': n_est,\n",
    "                'max_depth': max_d,\n",
    "                'min_samples_split': min_split,\n",
    "                'val_roc_auc': val_auc,\n",
    "                'val_f1': val_f1\n",
    "            })\n",
    "\n",
    "# Convert to DataFrame and find best parameters\n",
    "results_df = pd.DataFrame(results).sort_values('val_roc_auc', ascending=False)\n",
    "print(results_df.head(10).to_string(index=False))\n",
    "\n",
    "# Get best parameters\n",
    "best_params = results_df.iloc[0]\n",
    "print(f\"Best parameters:\")\n",
    "print(f\"n_estimators: {best_params['n_estimators']}\")\n",
    "print(f\"max_depth: {best_params['max_depth']}\")\n",
    "print(f\"min_samples_split: {best_params['min_samples_split']}\")\n",
    "print(f\"Validation ROC-AUC: {best_params['val_roc_auc']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf12dfb",
   "metadata": {},
   "source": [
    "Notice: The best parameters might change from run to run because we didn't use a specific random set when sampling from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed01c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest captures nonlinearities and interactions\n",
    "rf_clf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    random_state=42,\n",
    "    min_samples_split=5,\n",
    "    n_jobs=-1 # -1 is using all processors\n",
    ")\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Train set predictions\n",
    "rf_train_pred = rf_clf.predict(X_train)\n",
    "rf_train_proba = rf_clf.predict_proba(X_train)[:, 1]\n",
    "\n",
    "# Test set predictions\n",
    "rf_test_pred = rf_clf.predict(X_test)\n",
    "rf_test_proba = rf_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Random Forest (train set)\")\n",
    "print(\"Accuracy:\", round(accuracy_score(y_train, rf_train_pred), 3))\n",
    "print(\"F1:      \", round(f1_score(y_train, rf_train_pred), 3))\n",
    "print(\"ROC-AUC: \", round(roc_auc_score(y_train, rf_train_proba), 3))\n",
    "print(\"PR-AUC:  \", round(average_precision_score(y_train, rf_train_proba), 3))\n",
    "\n",
    "print(\"\\nRandom Forest (test set)\")\n",
    "print(\"Accuracy:\", round(accuracy_score(y_test, rf_test_pred), 3))\n",
    "print(\"F1:      \", round(f1_score(y_test, rf_test_pred), 3))\n",
    "print(\"ROC-AUC: \", round(roc_auc_score(y_test, rf_test_proba), 3))\n",
    "print(\"PR-AUC:  \", round(average_precision_score(y_test, rf_test_proba), 3))\n",
    "\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_test, rf_test_pred), display_labels=[\"Subscriber\", \"Customer\"]).plot(colorbar=False)\n",
    "plt.title(\"Random Forest confusion matrix\")\n",
    "plt.show()\n",
    "\n",
    "# ROC and PR curves side by side\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# ROC curve\n",
    "RocCurveDisplay.from_estimator(rf_clf, X_test, y_test, ax=axes[0])\n",
    "axes[0].plot([0, 1], [0, 1], linestyle='--', color='gray', label='No Skill Classifier')\n",
    "axes[0].set_title(\"Random Forest ROC curve\")\n",
    "axes[0].legend()\n",
    "\n",
    "# Precision-Recall curve\n",
    "no_skill = y_test.mean()\n",
    "PrecisionRecallDisplay.from_estimator(rf_clf, X_test, y_test, ax=axes[1])\n",
    "axes[1].axhline(y=no_skill, linestyle='--', color='gray', label='No Skill Classifier')\n",
    "axes[1].set_title(\"Random Forest Precision-Recall curve\")\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
